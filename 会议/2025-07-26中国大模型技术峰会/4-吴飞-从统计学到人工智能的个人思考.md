
# 统计建模中的两种文化


## 深度学习崛起前: 统计学习的奋斗

计算机→统计学→数学

- 在深度学习崛起前, 最后的工作方法是: 将一个任务拆成了多个统计学任务. 如 李飞飞团队在2010年于 ImageNet 的工作, 是在做“磨刀不误砍柴工”. 通过大量的手工构造的特征, 概率模型建模, 最后用一个简单支持向量机, 就实现了很好的效果
- 2021年的变革--AlexNet. AlexNet认为, 你研究者别再自己构造手工特征了, 我们通过大量数据, 用卷积网络提取特征, 最后加一个Softmax, 也很好的完成了工作. 实际上, 这样的工作也就是“特征-分类”的结果.
- 从这以后, 我们就不再太关注统计学、数学方面的内容了.

## 统计学习 != 深度学习

| 思考角度   | 传统统计学习                                 | 深度学习                                                    |
| ------ | -------------------------------------- | ------------------------------------------------------- |
| 参数性质   | 参数是随机变量或位置的量                           | 参数可优化的变量, 我显式概率假设                                       |
| 目标函数   | 最大似然函数或后验概率                            | 最小化经验损失                                                 |
| 不确定性建模 | 显式建模(置信区间、假设检验)                        | 隐式通过正则化式                                                |
| 理论保障   | 依赖大样本理论(如一致性、无偏性)                      | 依赖实验验证和泛化间隙                                             |
| 特点     | 假设驱动, 预设数据服从某种特殊的概率分布, 并解释“为何数据呈现这种规律” | 数据驱动, 不预设的分布形式, 而是直接通过算法从输入到输出的映射, 功能性是重要的, 而           |
|        |                                        | 如果数据有问题, 那么你的结果, 一定是空洞的, 一定是不好的. 如果你没有好的数据, 就不要开始深度学习工作 |

所以, 
- 统计学习的核心的推断, 试图回答"参数如何随数据变化"
- 深度学习的核心是逼近, 试图回答 “如何用参数化函数拟合数据”