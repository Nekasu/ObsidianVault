_文继荣_，中国人民大学高瓴人工智能学院执行院长

扩散模型往往被用于图像, 而非大语言, 那么“扩散”大语言模型是怎么回事呢？

这是一种新的大语言模型尝试--基于扩散模型的大语言模型.

研究的契机是这样一句话:

> 文字的顺序不影响阅读……

(实际上, 我在这里写的这段文字顺序没有错, 只是会议期间没有时间调换文字顺序, 就先这样记吧)

这样的现象表明, 文字是一个整体, 是受上下文影响的, 所以有了这样工作的想法.

报告提纲如下: 
- 研究动机: 自回归是不是通用人工智能生成式人工智能的唯一出路？
	- 生成模型的本质, 是学习一个高维概率分布. 
	- 基础生成模型, 一般具有三个要素: 
		- 网络结构的确定, 如 Transformer, 卷积网络, 感知机. 当前已趋于统一, 即Transformer
		- 数据规模的扩展, 也已经统一
		- 概率建模方法, 如 VAE/GAN/Flow, 再如 AR (自回归, 在语言上有优势)/Diffusion (在图像视频上有优势). 这一方面没有统一
		- 目前的工作往往是这三个方面的结合
			- 如 GPT, 就是 Transformer + AR
			- 如 Sora, 就是 Transformer + Diffusion

- 自回归, 是自然语言领域最常用的方法, 那么自回归是不是唯一途径呢? 不是的
	- 当前 LLM 模型往往出于两个公式
		- 目标函数： $\max_\theta E_{p_{data}(x)} <=> \min_\theta KL(p_{data}(x)\Vert p_{\theta}(x))$ , 也即最小化真实数据与模型参数所描述概率模型之间的差异.
		- 从左到右, 链式反应, 自回归模型: $p_{\theta}(x)=p_{\theta}(x^1)\prod_{i=2}^L p_{\theta}(x^i|x^1,\cdots,x^{i-1})$  , 这很正常, 因为我们人类的文字, 就是从左到右阅读的, 用这样的链式反应也很好理解
		-  许多良好的 LLM 工作, 其良好的原因在于“目标函数”, 而非“从左到右”的链式反应, 以下是两个例子. 
			- 在一般的大语言模型中, 可能出现 “A 是 B”, 但“B 不是 A”的“认知错误”. 所以第二个公式“从左到右”是有问题的.
			- 当 LLM 生成的文字长度越长, 那么所需要的算力越多, 这是由 Transformer 影响的.
		- 而 diffsuion 没有上述这两个问题.
			- 对于第一个问题, 由于扩散模型是从全局考虑, 逐步去噪的过程, 所以对文字的认知是“整体”的, 所以更好.
			- 对于第二个问题, 扩散模型生成数据是经过固定的 Step, 不管生成多大的数据, 只要经过固定的步骤就行, 所以更好.
				- 当存在大量所需生成内容时, 扩散模型会将生成内容变成多个“语言块”. 在每个“语言块”中, 实行扩散生成; 而在两个“语言块”间, 使用链式法则与自回归进行预测. 在这种情况下, 当“语言块”缩小至一个单词时, 就退化成了自回归. 


回头看, 自回归与扩散的未统一问题, 该学者认为, 是否可以用扩散统一概率建模问题？

实际上, 也有其他团队在做“用自回归统一概率建模”, 即“视觉语言微调”.