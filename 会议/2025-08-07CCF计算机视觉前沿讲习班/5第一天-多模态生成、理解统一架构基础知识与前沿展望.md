大语言模型→多模态理解、多模态生成→统一大模型 (多模态理解+生成)→具身智能、科学智能 AIforScience→世界模型

我们已经走过了语言大模型的路, chatgpt 3 就已经能做到很好的效果. 多模态理解与多模态生成也已经实现. 目前大模型在“使用同一个模型完成理解+生成任务”. 

当前的具身智能, 往往是一个机器人调用多个大模型或多个模型完成同一个任务, 而实际上一个大模型就已经需要运行较长时间, 这种情况下, 用多个大模型的机器人也则会具有更低的速度. 所以该讲师认为, 在这种“一个大模型能解决理解、生成所有任务”出现前, 具身智能的实现是困难的.

多模态目前存在很多问题.
1. 多模态不原生、多模态理解与生成割裂
	1. 多模态生成, 以 Diffusion 为主 (diffusion)是建模方式, 以 Transformer 作为模型结构
	2. 多模态理解, LLaVA 系列, 自回归建模方式, Transformer 作为模型结构
	3. 以上建模方式的不一致, 导致理解与生成割裂
		1. 生成未必理解、理解不能生成
		2. 建模方式不一样: 视觉生成依靠扩散模型, 视觉理解 LLM (自回归)
		3. 模型规模不一样: 视觉理解可以有千亿规模, 生成模型大部分数十亿百亿
	4. 所以我们希望他们能走到统一的路上.

老师认为, Diffusion 是结构推理, 而自回归是因果推理.

为何视觉任务要压缩, 而文本任务不需要压缩？
- 老师认为, 视觉图像本来就是低效的, 而文本是由人类 encode 后的凝练的非冗余的, “用最小的比特传递了最多的信息”. 
- 基于这种观点, 视觉这种“没有被编码过”的, 自然需要编码, 也即“压缩”; 而文字这种被人类 encode 过的信息
	- 图像中, 不是所有像素的重要性是一致的, 这就是信息的冗余, 所以需要编码压缩.