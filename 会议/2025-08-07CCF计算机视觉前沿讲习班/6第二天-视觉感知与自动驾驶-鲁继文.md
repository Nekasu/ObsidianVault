
计算机视觉好像没什么可做的了？

上一代人脸识别技术已经趋于完善, 而自动驾驶不一样. 自动驾驶是一个检验计算机视觉有效性的重要方法. 

在 2021 年语言大模型出来后, CV 领域的人需要面对一个问题: 什么时候有视觉大模型？如何验证视觉大模型？

鲁教授认为, 自动驾驶是一个复杂、困难、多任务、高精度要求的目标, 是一个验证计算机视觉、让计算机视觉学者有广阔探索空间的任务与学科. 

> “自动驾驶旨在实现感知、导航、控制、决策一体化的新一代智能系统.”--鲁继文

自动驾驶走到今天, 已经由计算机视觉为中心、为主导. 
- 马斯克认为, 做工程之前, 需要考虑任务的第一性. 他认为, 人类驾驶员主要依靠视觉来驾驶汽车, 所以计算机视觉也应该是自动驾驶的主导技术
- 基于激光雷达具有稀疏性, 难以识别行人等小物体, 而图像数据信息更丰富. 目前自动驾驶在逐渐淘汰激光雷达, 转向以激光雷达与视觉结合的方式.

自动驾驶研究现状:
- 感知
	- 三维目标检测. 其优点在于能有物体级别的精准定位, 而缺点在于只能看到前景信息, 没有背景信息, 无法建模物体形状
	- 三维占据预测: 其关键在于泛化能力. “虽然没有见过这个物体, 但是能知道那里有障碍物, 从而避开”
	- 三维语义分割
	- 三维场景表示: 如何表示一个三维场景？
		- 体素: 将空间用立方体的方式表示, 精准, 但数据量太大.
		- TPV: 将三维物体投影到三个平面, 降低数据量.
		- 三维高斯: 三维占据本质上是一个对三维空间的稠密表示. 而高斯混合开夜车万能近似任意分布, 可以只建模有物体的地方.
		- BEV: 忽略高度信息, 将三维物体投影到下平面上.
- 决策
- 生成: 计算机视觉的生成能力能弥补实际数据不足的问题, 如下雪天, 下雨天, 车祸前
	- 自动驾驶范式的演变: 以前是感知和决策分开, 而现在要做端到端的自动驾驶, 这需要大量三维感知标注, 需要大规模数据, 训练成本高
	- 利用生成视觉模型, 预测三维变化, 在与环境交互从完成决策
	- <mark style="background: #6495EDA6;">自动驾驶生成, 是一个未充分研究的新兴领域</mark>
	- 现有方法直上云霄使用数据集评估自动驾驶决策算法的效果, 而不能在真实交互环境下评估效果.
- 总结:
	- 感知模块以占用预测以及高效三维场景表示为核心
	- 决策模块往端到端的经济型方案发展
	- 生成模块依旧没有很好发展
	- 现有方法往往仅关注感知/决策/生成中的一部分
	- 生成式、自监督、空间感知是自动驾驶的发展方向, 大模型是自动驾驶的发展方向
		- 生成式能提供真实环境下缺少的数据
		- 自监督能提高数据的利用率
		- 空间感知能力是必由之路

大驾驶模型 Large Driving Model
- 现有自动驾驶模型: 自动驾驶任务适配语言大模型
- 大驾驶模型: 基于三维场景表示的自监督闭环驾驶模型
	- 三位场景表示, 即上述的空间感知
	- 自监督, 即上述提到的自监督
	- 闭环, 即上述提到的生成式模型

三维场景是自动驾驶的底层逻辑
- 以视觉为重心的自动驾驶发展脉络
	- 弥补激光雷达在场景表示上的弱点--提高上限
	- 利用大模型训练的神经网络来推理信息--达到上限

随后介绍了一系列论文工作