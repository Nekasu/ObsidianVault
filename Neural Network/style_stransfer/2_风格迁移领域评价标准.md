
>[!warning] 提示
>点击右上角「书本」![[Pasted image 20231125105318.png]]图标, 进入阅读模式, 以获得更好的阅读体验！

本文旨在探寻风格迁移的评价标准. 众所周知, 风格迁移领域评价标准众说纷纭, 本文力求整理风格迁移领域顶会顶刊上文章中使用的定量评价指标

# 广泛收集阶段

此阶段用于广泛收集各种风格迁移领域的评价标准

1. [x] 欺骗率
	1. 来源：Sanakoyeu A, Kotovenko D, Lang S, et al. A style-aware content loss for real-time hd style transfer[C]//proceedings of the European conference on computer vision (ECCV). 2018: 698-714.
	2. 原始论文中对于欺骗率的描述
		1. We use a VGG16 network trained from scratch to classify 624 artists on Wikiart. Style transfer deception rate is calculated as the fraction of generated images which were classified by the network as the artworks of an artist for which the stylization was produced.
		2. 翻译：我们训练了一个VGG16网络, 使其能够区分Wikiart数据集上624个艺术家的不同艺术作品. 风格迁移欺骗率是这样一个数：首先风格迁移欺骗率是一个分数, 它的分母是「所有生成的风格图像」, 它的分子是「生成的风格图像中, 被认为是艺术家创作的艺术作品的数量」. 这也就是说, 风格迁移欺骗率表示了「生成图像被认为是画家画出的, 而非生成的图像的比率」
		3. 被引用次数：226(2024-1-17)
2. [x] FID
	1. 来源：Heusel M, Ramsauer H, Unterthiner T, et al. Gans trained by a two time-scale update rule converge to a local nash equilibrium[J]. Advances in neural information processing systems, 2017, 30.
	2. 描述：FID（Fréchet Inception Distance）是一种用于评估生成模型性能的指标，特别是在生成对抗网络（GANs）的上下文中。它基于两个概率分布之间的 Fréchet 距离，其中一个分布是真实数据的分布，另一个是生成器模型生成的数据的分布。
	3. 被引用次数：10301(2024-01-17)
3. [x] LPIPS（Perceptual Image Patch Similarity）
	1. 来源：Zhang R, Isola P, Efros A A, et al. The unreasonable effectiveness of deep features as a perceptual metric[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 586-595.
	2. 描述：LPIPS是一种用于评估图像质量和感知相似性的指标。与传统的像素级或结构相似性指标不同，LPIPS 主要关注图像在感知上的相似性，考虑人类视觉系统对图像中的感知信息的感知。
	3. 被引用次数：7428(2024-01-17)
4. [x] SSIM(Structural Similarity Index)
	1. 来源：
	2. 首次使用：An J, Huang S, Song Y, et al. Artflow: Unbiased image style transfer via reversible neural flows[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 862-871.
		1. 描述：受原始论文的启发，我们采用结构相似度指数（SSIM）和原始内容与风格化图像之间的内容损失作为度量来衡量风格迁移中内容信息保存的性能。
5. [x] Gram矩阵
	1. 来源
	2. 使用例子：An J, Huang S, Song Y, et al. Artflow: Unbiased image style transfer via reversible neural flows[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 862-871.
		1. 描述：为了衡量风格转移算法创建艺术效果的能力，受[32]的启发，我们使用风格图像和风格化图像之间的格拉姆矩阵的均方误差。
6. [x] Content Loss
	1. 来源：不知道
	2. 描述：![[Pasted image 20240117163602.png]]
		1. 本图来自文章Deng Y, Tang F, Dong W, et al. Stytr2: Image style transfer with transformers[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 11326-11336.
	3. 使用这个标准的文章
		1. Li D, Luo H, Wang P, et al. Frequency domain disentanglement for arbitrary neural style transfer[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(1): 1287-1295.
7. [x] Style Loss
	1. 来源：Huang X, Belongie S. Arbitrary style transfer in real-time with adaptive instance normalization[C]//Proceedings of the IEEE international conference on computer vision. 2017: 1501-1510.
		1. 描述：![[Pasted image 20240117161955.png]]
			1. 本图来自文章Deng Y, Tang F, Dong W, et al. Stytr2: Image style transfer with transformers[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 11326-11336.
	2. 使用这个标准的文章：
		1. Li D, Luo H, Wang P, et al. Frequency domain disentanglement for arbitrary neural style transfer[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(1): 1287-1295.
8. [x] PD(pixel distance)
	1. 来源：Wang Z, Zhao L, Chen H, et al. Diversified arbitrary style transfer via deep feature perturbation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 7789-7798.
		1. 描述：![[Pasted image 20240117162618.png]]
	2. 使用这个标准的文章：
		1. Cheng J, Wu Y, Jaiswal A, et al. User-controllable arbitrary style transfer via entropy regularization[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(1): 433-441.
9. [ ] Content Fidelity (CF), 内容保真度
	1. 来源：Wang Z, Zhao L, Chen H, et al. Evaluate and improve the quality of neural style transfer[J]. Computer Vision and Image Understanding, 2021, 207: 103203.
	2. 描述：![[Pasted image 20240117165835.png]]
		1. 图像来自提出CF的原始论文, 即“来源一项”的文献
		2. 除此之外, 本文还提出了两个其他的评价标准
			1. Global Effects (GE).
			2. Local Patterns (LP).
10. [ ] $L_{sim}$
	1. 来源：Tang H, Liu S, Lin T, et al. Master: Meta Style Transformer for Controllable Zero-Shot and Few-Shot Artistic Style Transfer[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 18329-18338.
	2. 描述：
		1. ![[Pasted image 20240117171741.png]]
		2. 图像来自原始论文, 即“来源一项”的文献