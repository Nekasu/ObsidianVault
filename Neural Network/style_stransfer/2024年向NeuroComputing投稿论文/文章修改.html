<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/Template/styles.css">
    <title>文章修改</title>
</head>
<body>
    <div class="container">
        <div class="note-section">
            <h1>文章修改要求</h1>
            <p>根据<a href="./20241126接受审稿意见如下.md">本人总结的文章修改意见</a>与<a href="./NEUCOM-D-24-08078.pdf">原始文章修改意见邮件</a>, 可以总结审稿人对该文章具有以下要求：</p>
            <ol>
                <li>Abstract与Introduction: 需要明确为何现在需要写这篇综述, 即明确本文综述的意义</li>
                <li>Mainbody: 
                    <ol>
                        <li>需要扩充文章中涉及的领域, 如3D风格迁移、visual reasoning、image transfer methods的成果, 需要补充2022-2024年的相关文章. <span style="color: #FF5582A6;">此处编辑部给出了一些参考文献.</span></li>
                        <li>缺少最新风格迁移的客观指标对比
                            <ol>
                                <li>实际上, 我们并没有这样的对比.<span style="color: #FF5582A6;">在给编辑部中的回复中, 应该指出这一点</span></li>
                                <li>同时, 应加上最近一些年风格迁移的可视化结果作为补充</li>
                            </ol>
                        </li>
                        <li>缺少领域自适应相关的内容</li>
                        <li>缺少visual reasoning, Image transfer methods相关成果: <span style="color: #FF5582A6;">审稿人2 给出了一些文章. 阅读这三篇文章, 以了解审稿人2是在表达什么意见.</span></li>
                    </ol>
                </li>
                <li>挑战与展望部分
                    <ol>
                        <li>可解释性与可控制性需要进一步分类：xxx类模型试图解决xxx问题, 但忽视了xxx方面的影响. 而xxx类则从xxx角度考虑问题, 试图克服xxx问题, 但留下了xxx影响</li>
                        <li>针对不同方法给出高瞻远瞩的讨论
                            <ol>
                                <li>基于扩散模型的方法具有什么优势, 但是xxx</li>
                                <li>基于Transformer的方法具有xxx优势, 但是xxx</li>
                                <li>总体来说xxx</li>
                                <span style="color: #FF5582A6;"><li>此部分编辑审稿人1给出了一些文章, 应该将这些文章加到自己的文章中</li></span>
                            </ol>
                        </li>
                        <li>现实应用中, style transfer具有什么阻碍？</li>
                    </ol>
                </li>
            </ol>
        </div>
        
        <div class="note-section">
            <h1>文章修改方案</h1>
            根据以上编辑部要求, 从而可以对文章中各个部分进行修改, 根据文章原章节, 可填充修改方案如下： 
            <ol start="0">
                <li>Abstract
                    <ul>
                        <li>
                            <del>明确动机：为何要写这篇综述. 现在为何需要这篇综述. 可以参考其他综述.(不要太长, 一般是Inroduction部分的总结)</del>
                        </li>
                    </ul>
                </li>
                <li>Introduction
                    <ul>
                        <del><li>明确动机：为何要写这篇综述. 现在为何需要这篇综述. 可以参考其他综述.(在Introduction中, 应该详细介绍这一部分, 这是Intorduction中应该介绍的)</li></del>
                    </ul>
                </li>
                <li>Traditional Style Transfer
                    <ul>
                        <del><li>传统风格迁移部分无须更改</li></del>
                    </ul>
                </li>
                <li>Neural Style Transfer
                    <ul>
                        <li>查找更细分领域的风格迁移论文, 着重寻找2022-2024年细分领域(如3d风格迁移、视频风格迁移)下的风格迁移论文. 添加到对应的章节中
                            <ul>
                                <li>
                                如3d风格迁移、视频风格迁移、跨域风格迁移、交互式风格迁移、多模态风格迁移(如音乐风格迁移为视觉风格)
                                </li>
                                <span style="color: #FF5582A6;"><li>审稿人2针对这一部分给出了一些参考文章, 应该将这些文章添加到自己的引用中</li></span>
                            </ul>
                        </li>
                        <li>添加visual reasoning, Image transfer methods相关成果: <span style="color: #FF5582A6;">审稿人2 给出了一些文章. 阅读这三篇文章, 以了解审稿人2是在表达什么意见.</span></li>
                        <li>添加领域自适应与风格迁移的文章</li>
                    </ul>
                </li>
                <li>Ebaluation Metrics
                    <ul>
                        <li>修改原本统计风格迁移参数指标的表格, 将其中原本表示是否使用该评价指标的占位符0/1修改为文章中对应的参数.</li>
                        <li>可选：添加一些近年来的风格迁移结果作为“客观对照”, 可以参考一些其他的综述文章. <span style="color: #FF5582A6;">并最终在review中指出“没有客观评价标准”这一点. 所以使用了上述两种方法代替.</span></li>
                    </ul>
                </li>
                <li>Frontiers and Challenges
                    <ul>
                        <li>完善“可解释性与可控制性”一栏. 从模型角度给出分类：某些模型可能在解释某项原理方面具有帮助, 而其他模型则有另外的优势.
                            <ul>
                                <span style="color: #FF5582A6;"><li>审稿人1针对这一部分给出了一些参考文献的建议, 应该将这些文章添加到自己的引用中</li></span>
                            </ul>
                        </li>
                        <li>最终应给出高瞻远瞩的讨论：什么模型具有什么优势, 但也具有什么劣势</li>
                        <li>与现实应用结合：风格迁移在现实应用中具有什么挑战？
                            <ul>
                                <li>这一部分可以与Introduction中介绍的“风格迁移实际用途结合”, 从这些文章入手, 看看这写文章中在应用时有什么缺陷(如必须输入什么掩膜之类的)</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li>Conclusion</li>
            </ol>
        </div>
        
        <div class="note-section">
            <h1>文章修改进度记录</h1>
                <div class="note-section" style="background-color: #6495ED30;">
                    <h2>Introduction修改</h2>
                    <h3>原始草稿</h3>
                    <p>Introduction部分, 在倒数第一段前添加一个新的自然段, 加上本文的动机：介绍前人的综述工作(从论文库中找). 大致按以下流程进行：</p>
                    <p>当前, 有一些论文总结了风格迁移领域的发展与现状. </p>
                    <p>Jan(21kyprianidis2012state)等人的文章是风格迁移领域一篇早期的综述. 该文章着重于介绍基于传统方法的风格迁移任务, 而现在的风格迁移任务多是以神经网络为基础的, 所以这篇文章缺少了大量与神经网络相关的内容, 对现今风格迁移领域的指导意义有限.</p>
                    <p>Jing(79jing2019neural)等人在文章中详细总结了风格迁移成果, 并将神经风格迁移任务分成了多个步骤, 从而进一步介绍各个步骤的不同方法. 尽管这篇文章十分经典, 且对初入领域者有较高的指教价值, 但是在该文章发表后, 计算机视觉领域迎来了Transformer与扩散模型两个对生成式AI具有重大意义的模型, 导致这篇文章在这方面有所欠缺.</p>
                    <p>Qiang等人(81cai2023image)的文章是一篇较新的风格迁移综述, 该文章从传统方法与神经网络方法为切入点, 着重介绍了基于GAN的风格迁移成果. 与Jing(79jing2019neural)等人的文章类似, 本文也未介绍基于Transformer或扩散模型的风格迁移成果</p>
                    <p>在上述三篇综述缺少当前部分流行方法的同时, 依旧存在另一个不足, 回避了风格迁移领域的客观评价指标问题. 风格迁移任务的最终目标是生成一张具有风格图像风格信息与内容图像内容信息的风格化图像, 而这种风格化图像往往具有一定的艺术性, 这种艺术性是难以用客观评价指标衡量的. 但即便如此, 风格迁移领域的文章也试图通过一些客观评价标准以评判自身工作的好坏, 尽管使用的评价标准并未统一. </p>
                    <p>本文以弥补上述缺陷作为核心出发点, 将风格迁移工作以发展的时间顺序分成多个阶段, 并介绍了以往成果中缺失的基于Transformer与扩散模型的风格迁移成果. 同时, 本文还分析了当前风格迁移成果使用的各种客观评价指标, 供研究人员参考.</p>
                    <h3>GPT润色</h3>
                    <p>近年来，风格迁移领域的综述性研究取得了显著进展，为研究人员提供了宝贵的参考。然而，这些综述仍然存在一定的局限性。例如，Kyprianidis 等人(21kyprianidis2012state)撰写了一篇早期的风格迁移综述，主要集中在基于传统方法的风格迁移任务上，而这些方法已无法满足当前以神经网络为基础的任务需求。尽管 Jing 等人(79jing2019neural)在其经典文章中系统总结了神经风格迁移方法并将任务分解为多个步骤，这一研究对初学者有极高的指导价值，但在Transformer与扩散模型广泛应用后，本文在此方面的覆盖相对有限。此外，Cai 等人(81cai2023image)的文章则更多地聚焦于基于生成对抗网络（GAN）的风格迁移成果，但同样未对最新的Transformer和扩散模型的成果展开深入讨论。</p>
                    <p>更为关键的是，这些综述在探讨风格迁移的客观评价标准方面均显不足。风格迁移的目标是生成融合风格与内容特征的图像，但其艺术性往往难以用统一的客观指标加以量化。然而，领域内的许多研究仍然尝试通过某些客观评价标准对模型的优劣进行评估，但这些标准的使用缺乏统一规范。</p>
                    <p>为弥补上述不足，本文以发展的时间顺序对风格迁移的研究工作进行了分阶段的综述，并系统补充了基于Transformer和扩散模型的最新成果。此外，本文深入分析了当前风格迁移研究中采用的各种客观评价指标，旨在为研究人员提供全面的参考。</p>
                </div>
            <div class="note-section" style="background-color: #ffff3423;">
               <h2>Abstract修改</h2> 
               <h3>GPT润色</h3>
               <ul>
                <li>要求：太长了, 可以不介绍其他文章的缺陷, 而是直接说明“in this paper, we aim to provide.....”</li>
                <li>生成结果：Image style transfer is a technique that combines the content of a real photograph with the artistic style of another image to create a new and stylized image. In this paper, we aim to provide a comprehensive review of the field, tracing its development from traditional methods to modern neural network-based approaches. We focus on recent advancements utilizing Transformers and diffusion models, which represent significant progress in generative AI. Furthermore, we systematically analyze the objective evaluation metrics employed in style transfer, offering valuable insights for researchers. Finally,this paper highlights unresolved issues and suggests future directions to foster innovation in style transfer techniques.</li>
               </ul>
            </div>
            <div class="note-section" style="background-color: #12ff1220;">
                <h2>Mainbody修改</h2>
                <h3>细分领域文章阅读与记录</h3>
                该部分中, 用红笔标出的为审稿人推荐加入的文章
                <h4>3D风格迁移</h4>
                <ol>
                    <li>
                        <span style="color: #FF5582A6;">StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields</span>
                    </li>
                    <li>
                        <span style="color: #FF5582A6;">StyleFormer: Real-Time Arbitrary Style Transfer via Parametric Style Composition</span>
                        <ol>
                            <li>应添加于3.3.3 基于注意力机制的风格迁移一段的开篇, 作为第一篇文章讲解.</li>
                            <li>本文发表于2021年, 其核心目标是实现任意且实时的风格迁移.<span style="color: #6495EDA6;">实际上并不是3D风格迁移.</span></li>
                            <li>本文观察到了Transformer的多头注意力机制能捕获长程依赖性的特点, 并认为该特点使得Transformer在捕捉全局风格信息与内容语义上具有较大优势. 本文使用Transformer的主要目的是提升风格迁移过程中对全局风格信息的建模能力. </li>
                            <li>
                                本文网络架构可以描述为Encoder-基于Transformer的风格迁移核心-Decoder. 除了基于VGG16的Encoder与Decoder之外, 本文网络核心可以细化为三个部分：1. Style Bank Generation Module 2. 基于Transformer的风格组合模块Transformer-driven Style Composition Module, 3. 参数化内容调制模块(Parametric Content Modulation Module)
                                <ul>
                                    <li>Style Bank Generation Module: 该模块以风格图像的编码结果作为输入, 并将其表示为有限数量的风格代码（Style Codes），每个代码包含一个风格键(Key)以及对应的风格值(Value). 风格键(Key)用于表示风格特征, 而对应的风格值(Value)是一个仿射变换矩阵, 用于根据风格特征调整内容图像.</li>
                                    <li>Transformer-driven Style Composition Module: 该模块根据内容特征动态组合风格代码(Style Codes)，通过多头注意力机制实现风格与内容的全局一致性。该模块使用风格键(Key)和风格值(Value)分别作为Transformer的Key和Value，将内容特征作为Query。并多头注意力机制（Multi-head Attention）学习风格与内容的全局关联，为不同组别生成内容一致的仿射系数, 从而确保风格迁移结果在全局上保持风格特征的细腻表达，同时语义结构与内容特征一致。</li>
                                    <li>Parametric Content Modulation Module模块将Transformer-driven Style Composition Module生成的仿射系数应用于内容特征，完成风格化特征的生成. Decoder以该风格化特征作为输入, 解码为最终的风格化图像.</li>
                                </ul>
                            </li>
                        </ol>
                    </li>
                </ol>
                <h4>视频风格迁移</h4>
                <h4>交互式风格迁移</h4>
                <h4>多模态风格迁移</h4>
                <h3>visual reasoning与Image Transfer Methods领域文章阅读与理解</h3>
                <h4>审稿人2的实例文章阅读</h4>
                <ol>
                    <li>Diffusion Attack: Leveraging Stable Diffusion for Naturalistic Image Attacking</li>
                    <li>Visual Recognition with Deep Nearest Centroids</li>
                    <li>Learning Equivariant Segmentation with Instance-Unique Querying</li>
                </ol>
                <h4>总结上述文章的规律</h4>
                <h4>类似文章阅读</h4>
            </div>
        </div>
    </div>
</body>
</html>