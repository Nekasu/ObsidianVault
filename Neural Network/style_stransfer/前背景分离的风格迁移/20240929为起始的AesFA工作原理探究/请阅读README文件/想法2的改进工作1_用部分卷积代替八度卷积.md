---
parent: "[[自己想法构建]]"
collections:
  - 风格迁移综述撰写
---

>[!warning] 提示
>推荐使用 [obsidian 软件](https://obsidian.md/), 以获得最好的阅读体验
>点击右上角「书本」![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240910163022.png)图标, 进入阅读模式, 以获得更好的阅读体验！
>
>作者：Nekasu/周肖桐


## 代码适配工作

1. 现在进行适配工作：将 forward 函数中涉及 `PartialConv` 的部分改写, 改变其输入与输出
	1. 因为在使用 `PartialConv` 时, 需要传入一个掩膜, 并且在最后会返回一个掩膜. 这样的操作与传统的卷积 `nn.Conv2d` 是有很大差别的.
	2. 所以除了需要修改 `__init__` 函数中的卷积定义以外, 还需要修改所有设计部分卷积的类中的 `forward` 函数
	3. 2024 年 10 月 29 日-16:08 周二：为了更好的修改, 我们以自顶向下的方式进行. 具体来说, 就是先检查主程序 `train.py` 中 `main` 函数是否有需要修改的, 如果有, 则进行修改. 如果 `train.py` 中使用了一些其他更基础的类, 则先进行这些更基础的类的修改.
		1. 在修改时, 为了明确自己的工作状况, 请随时完善一个工作栈, 记录当前的工作进度. 记录在 [[AesFA代码修改工作栈.canvas|AesFA代码修改工作栈]]中

## 想法的完善：Decoder 与 Encoder 的区分

本次想法的完善记录于 2024-10-30 21:58 周三

在 Decoder 中, 是否需要使用带有掩膜的 OctConv？实际上, 我认为不再需要了.
1. 由于原始的 Encoder 会编码掩膜中的信息, 无法适配具有掩膜的图像.
2. 但是 Decoder 中, 使用的卷积核是自适应卷积核, 来自风格图像编码后的结果, 所以无须重新使用掩膜

故而在实现时可以有以下修改：

### 修改 1 ：为 Encoder 与 Decoder 分别设计八度卷积

1. 为 Encoder 和 Decoder 分别设计八度卷积
	1. Encoder 中的 OctConv 被称作 PartialOctConv, 与普通 OctConv 的区别是该 PartialOctConv 将所有的 `nn.Conv2d` 改成了自己编写的 `PartialConv`.
	2. Decoder 中的 OctConv 被称做 OctConv, 即普通八度卷积.
	3. 实现以上想法, 需要如下步骤
		1. [x] 更改自己修改后的 OctConv 名字为 PartialOctConv, 并将 Encoder 中所有的 OctConv 改成 PartialOctConv
			1. [x] 重新测试 Encoder 类的运行情况.
		2. [x] 从原始的 AesFA 仓库中复制一个原始的 OctConv, 并将检查 Decoder 中所有八度卷积, 查看是否有纰漏
			1. [x] Decoder 中不需要部分卷积.

### 修改 2 ：区分 StyleEncoder 类与 ContentEncoder 类

#### 修改 2 的基础思路

1. 在 Encoder 中, 对于内容图像而言, 实际上并不需要分前景与背景. 而是：
	1. 假设现有风格图像的前背景分离结果：背景风格信息与前景风格信息
	2. 利用风格图像的背景风格信息与前景风格信息分别对「整个内容图像」进行风格迁移
	3. 得到两种不同风格的「完成风格化图像」后, 再根据「原始内容图像」生成掩膜
	4. 利用内容图像的掩膜对这两种不同的风格图像处理、拼接, 得到最终的结果.

#### 修改 2 的实现思路

1. 为了实现以上想法, 需要有如下步骤
	1. [x] 为风格图像特别设立一个 Encoder 类, 命名为 StyleEcoder, 其中使用 PartialOctConv 进行卷积
	2. [x] 将原始的 Encoder 更名为 ContentEncoder, 其中使用普通的 OctConv 进行卷积.
	3. [x] 修改 `model.py → AesFA 类`, 使用 StyleEncoder 与 ContentEncoder 分别处理风格图像与内容图像, 而非使用单一的 Encoder 类处理这两类图像.
		1. [x] 修改 `__init__` 函数
		2. [x] 修改 `forward` 函数, 在传入的 `data` 变量中读取 style_mask 信息.
			1. 修改 forward 函数, 就是在看调用 AesFA 类的实例时, 用到了什么信息.
				1. 在 `model.py → AesFA类 → train_step函数的定义` 中, 调用了 forward 函数.
			2. 因此, 了解调用 AesFA 类的实例时, 用到了什么信息, 就是需要了解 `train_step` 函数在调用时, 输入了什么内容
				1. `train_step函数` 在 `train.py` 中以 `train_dict = model.train_step(data)` 调用.
					1. 返回的 `train_dict` 中包含了损失函数值、原始风格图像以及风格化图像以及他们的更细节信息
			3. 因此了解 `train_step` 函数在调用时, 输入了什么内容, 就是需要了解输入数据 `data` 
				1. `data` 在 `train.py` 文件中以 `for i, data in enumerate(data_loader_train):` 语句的形式存在
			4. 因此要了解 `data` 是什么类型的数据就是需要了解 `data_loader_train`
				1. `data_loader_train` 在 `train.py` 中以 `data_loader_train = torch.utils.data.DataLoader(...)` 的形式存在
			5. 因此要了解 `data_loader_train` 就是需要了解 `train_data`
				1. `train_data` 在文件 `train.py` 中以 `train_data = DataSplit(config=config, phase='train')` 的定义存在
			6. 因此要了解 `train_data` 就是要了解 `DataSplit` 类
				1. `DataSplit` 类是一个定义在 `DataSplit` 文件中的类, 该类用于读取数据
			7. 结合以上逻辑推断, 可以说明：
				1. 修改 `forward` 函数, 就是需要修改 `DataSplit.py → DataSplit类` 
			8. [x] 具体步骤如下：
				1. [x]  向  `DataSplit.py → DataSplit类 → __init__` 函数中添加内容, `if phase == 'train'` 条件下、`Style Image data` 注释中的内容, 具体来说 , 就是在处理风格图像时, 同时将其对应的掩膜一并处理
				2. [x] 向 `DataSplit.py → DataSplit类 →__getitem__` 函数添加内容, 具体来说, 就是在读取风格图像时, 同时将其对应的掩膜一并读取
			9. [x] git checkout 与 git switch 的区别
2. 2024-11-03 19:47 周日：上述想法的代码编写完毕, 并上传至 github 如下链接

```cardlink
url: https://github.com/Nekasu/PartialOct
title: "GitHub - Nekasu/PartialOct: A repository for PartialOctConv 佛"
description: "A repository for PartialOctConv 佛. Contribute to Nekasu/PartialOct development by creating an account on GitHub."
host: github.com
favicon: https://github.githubassets.com/favicons/favicon.svg
image: https://opengraph.githubassets.com/59b8a17aa3465d45da8f59d5ccc80ade1415b0d1d95276961550a3705f7e37b1/Nekasu/PartialOct
```

### 实验

#### 数据准备

现在为了能够跑出实验, 我们需要数据如下：
- [x] 内容图像
	- 内容图像使用业内常用的 MSCOCO, 该数据集存储在 Yuhui_4090 服务器, 路径为`/mnt/sda/Dataset/Detection/COCO/train2017`
- [ ] 风格图像
	- 想法：
		- 风格图像根据一开始的想法, 选择增强后的敦煌图像
			- 2024-11-04 0:35 周一：可以考虑使用沙画作为一种风格. 沙画作为一种强主体, 弱背景的艺术风格, 与“前背景分离的风格迁移工作”具有大量的相似之处, 固而可以进行该风格的尝试, 可以阅读以下两个网站内容获取灵感
			- [DS 变沙画-PaddleHub 的迁移训练 style Transfer 图像迁移](https://aistudio.baidu.com/projectdetail/2012947?channelType=0&channel=0)
			- [# Mural-Gan](https://github.com/thomas-yanxin/Mural-Gan)
		- 由于老师需要增强后的结果, 所以需要处理图像, 增强其饱和度.
		- 根据 chatgpt 的建议, 需要收集至少 200~500 张图像
	- 获取：
		- [ ] 阅读知网相关论文, 查看是否有敦煌研究论文, 是否有数据集提供
		- [ ] 访问敦煌官网, 根据云璃配色截取敦煌壁画的图像
		- [ ] 使用 Google、百度等搜索工具, 直接获取
		- [ ] 仿照论文“Xu Z, Zhang C, Wu Y. Digital inpainting of mural images based on DC-CycleGAN\[J\]. Heritage Science, 2023, 11 (1): 169.”中的数据获取方式, 从一些书籍中直接扫描获取
			- [ ] 或直接向该论文作者“Zhigang Xu”老师的[邮箱](xzg_cn@163.com)发送邮件, 以请求数据集.
- [ ] 风格图像掩膜
	- 想法：
		- 风格图像掩膜需要根据风格图像确定, 且需要做到一一对应. 当风格数据集确定, 则该掩膜数据的原来便可确定
	- 获取
		- [ ] 使用图像分割网络, 分离风格图像的前景与背景.
		- [ ] 使用 photoshop 的批处理功能, 对上述图像进行处理.