
>[!warning] 提示
>点击右上角「书本」![[Pasted image 20231125105318.png]]图标, 进入阅读模式, 以获得更好的阅读体验！

> [!error] 原始论文引用信息
> Chandran P, Zoss G, Gotardo P, et al. Adaptive convolutions for structure-aware style transfer[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021: 7972-7981.

本文是一篇对于 AdaIN 的改进文章, 这一点本文直接指出了. 本文发表与 2021 年, 可以认为 AdaIN 依旧有挖掘的空间. AdaIN 有继续挖掘的空间, 即使用均值与方差等具有图像统计信息量的值进行风格迁移是一个可继续探索的方案.

## 网络结构分析

网络结构如下所示：
![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240417164047.png)

现进行简单分析

### 整体结构分析

网络从整体来看分为三个主要部分
1. 风格图像处理部分
2. 内容图像处理部分
3. 卷积核预测网络部分

三个部分如下图所示：
![500](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240417164745.png)

由于内容图像处理部分依赖于风格图像处理部分, 所以先对图像靠下的“风格图像处理部分”进行思考与分析

### 风格图像处理

风格图像处理部分用于将风格图像编码为风格描述符 $\mathcal{W}$, 该描述符将作为卷积核预测网络的输入, 用于生成卷积核预测网络. 故而风格图像处理部分的作用是获取风格图像的编码信息.

### 内容图像处理

内容图像处理部分用于将内容图像进行风格迁移的工作. 内容图像处理网络采用了经典的“编码器-解码器”结构, 本文最主要的创新点在解码器上, 所有的其他网络均是为了解码器 $D$ 服务的. 

# 收获与总结

1. 学习了两个新的概念
	1. [[9_深度可分离卷积]]
	2. [[8_感受野]]
	3. 本文使用局部卷积核+AdaIN 式局部统计参数调整的形式, 实现了风格迁移
		1. 利用了卷积核的局部处理能力做到了结合全局信息与局部信息
2. 本文采用的是联合训练的方式
	1. 中途没有一点点人为的干预？
		1. 是的, 作者仅仅是设计了这个网络, 希望他能做到局部处理的效果
		2. 如果我们需要设计网络, 首先需要知道的, 就是现在网络拥有什么组件, 各个组件的功能是什么, 具有什么样的效果.
	2. 本文从什么角度出发, 设计的这个网络？如果是我, 从相同的角度, 能得到什么结果？
		1. 本文考虑到 AdaIN 网络中存在的缺陷：仅仅关注了全局信息, 而未关注局部信息.
		2. 如果是我, <mark style="background: #FFB8EBA6;">我应该如何使网络更加关注局部信息</mark>？
			1. 注意力机制, 使网络注意到某个局部的信息
			2. 特定位置的卷积核, 使网络能够关注某个局部的信息
		3. GPT 给出的建议如下：
			1. 在神经网络中实现局部关注的技术有很多种。以下是一些常用的技术：
				1. **空间注意力机制（Spatial Attention Mechanism）：** 空间注意力机制允许网络在处理图像时关注特定区域。这通常通过在网络中引入注意力模块来实现，这些模块根据输入图像的内容自适应地调整权重，以便更多地关注感兴趣的区域。常见的空间注意力机制包括注意力机制（Attention Mechanism）、自注意力机制（Self-Attention Mechanism）和空间注意力机制（Spatial Attention Mechanism）。
				2. **区域建议网络（Region Proposal Network，RPN）：** 区域建议网络是一种常用的目标检测技术，用于生成图像中可能包含对象的候选区域。这些候选区域可以被视为网络的局部关注区域，从而使网络能够专注于可能包含感兴趣对象的区域进行进一步处理。
				3. **局部卷积（Local Convolution）：** 局部卷积是一种卷积操作，它只在输入图像的局部区域上进行卷积，而不是整个图像。通过在卷积核中引入局部区域的掩码或权重，可以实现局部关注的效果。
				4. **空间金字塔池化（Spatial Pyramid Pooling）：** 空间金字塔池化是一种用于提取图像局部信息的技术。它将输入图像划分为多个不同大小的子区域，并对每个子区域进行池化操作，从而捕获不同尺度的局部信息。
				5. **区域注意力网络（Region Attention Network）：** 区域注意力网络是一种结合了空间注意力机制和区域建议网络的技术。它利用区域建议网络生成的候选区域，并通过空间注意力机制对这些区域进行加权，以提高对感兴趣区域的关注程度。
			2. 这些技术可以单独或者组合使用，以实现网络对图像局部信息的关注和处理。选择合适的技术取决于具体的任务和需求。
3. 对于训练的思考
	1. 整个网络是联合训练得到的, 基于对某个特定的损失函数, 优化整个网络
	2. 这点可以使工作难度大大降低, 研究人员仅仅需要搭建神经网络结构, 设计损失函数即可
4. 对于创新的思考
	1. 本文主要对「编-解码器」结构中的解码器进行了修改, 那么我能否对编码器进行改进, 使用他人研究的编码器结构
	2. 或者使用更先进的编码器 (从图像识别、分类、分割领域借鉴), 使用新型网络得到更好的性能

应建立自己的知识库：什么方法可以做到局部处理, 什么方法可以做到全局处理.