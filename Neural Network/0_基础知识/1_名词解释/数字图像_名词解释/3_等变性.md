
>[!warning] 提示
>点击右上角「书本」![[Pasted image 20231125105318.png]]图标, 进入阅读模式, 以获得更好的阅读体验！

- 本人首次从下述文章中了解到该名词：
	- Park T, Efros A A, Zhang R, et al. Contrastive learning for unpaired image-to-image translation\[C\]//Computer Vision–ECCV 2020: 16 th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part IX 16. Springer International Publishing, 2020: 319-345.
- 原文如下：
	- An interesting alternative approach is to encourage relationships present in the input be analogously reflected in the output. For example, perceptually similar patches within an input image should be similar in the output [88], output and input images share similar content regarding a pre-defined distance [5,68,71], vector arithmetic between input images is preserved using a margin-based triplet loss [2], distances between input images should be consistent in output images [4], <mark style="background: #6495EDED;">the network should be equivariant to geometric transformations</mark>

这句话中的“network should be equivariant to geometric transformations” 意思是神经网络应该对几何变换保持**等变性**。

具体来说，等变性（equivariance）指的是当输入数据经过某种几何变换（如平移、旋转、缩放等）时，网络的输出也应该以一种对应的方式变化。

例如，如果一个图像在输入时发生了旋转，网络的输出也应该相应地旋转，而不是完全不同的结果。换句话说，网络的输出应该“跟随”输入的几何变换，保持一种一致性。

通过确保网络对几何变换具有等变性，可以提高模型在处理不同视角或形状变化的输入时的表现，使得模型更具鲁棒性。这种特性在许多计算机视觉任务中非常重要，因为实际应用中的图像往往会受到各种几何变换的影响。

总结来说，这句话强调的是设计一个神经网络，使得它在面对几何变换时，能够产生相应一致的输出，从而保持输入和输出之间的关系。