# 定义与三要素

统计学习（statistical learning）是关于计算机基于数据, 构建概率统计模型, 并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习（statistical machine learning）。

从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的；

并且假设要学习的[[附录_名词解释#模型|模型]]属于某个函数的集合，称为假设空间（hypothesis space）； ^2d755f

应用某个评价准则（evaluation criterion），从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据（test data）在给定的评价准则下有最优的预测；

最优模型的选取由算法实现。

这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，称其为统计学习方法的三要素，简称为模型（model）、策略（strategy）和算法（algorithm）。

# 统计学习的对象

统计学习的对象是数据（data）。
它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。作为统计学习的对象，<mark style="background: #FFB8EBA6;">数据是多样的，包括存在于计算机及网络上的各种数字、文字、图像、视频、音频数据以及它们的组合。</mark>

# 统计学习的基本假设

统计学习关于数据的基本假设是同类数据具有一定的统计规律性，且输入$X$与输出$Y_p$具有[[附录_名词解释#联合分布率P(X,Y_t)|联合概率分布]], 这是统计学习的基本假设

# 统计学习的分类

统计学习由监督学习（supervised learning）、非监督学习（unsupervised learning）、半监督学习（semi-supervised learning）和强化学习（reinforcement learning）等组成。

# 统计学习的总目标
  
统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。

## 监督学习的目标

监督体系的目的在于学习一个由输入到输出的映射, 这一映射由模型来表示.

`学习的目的`在于找到最好的这样的模型. 这个模型可以是一个映射函数$Y_p=f(X)$, 也可以是一个概率分布$P(Y_t|X)$

其中, $X$表示输入, $Y_p$表示预测的结果, $Y_t$表示真实数据

## 联合分布率P(X,Y_t)

在统计学习中，$P(X, Y_t)$ 表示的是联合概率分布，其中的 $Y_t$ 表示真实的标签或目标值，<mark style="background: #FF5582A6;">而不是预测的结果</mark>。这个联合概率分布描述了输入 $X$ 和对应的真实标签 $Y_t$ 的分布情况。统计学习的目标是通过学习样本数据的特征和标签之间的关系，建立一个模型来预测未知数据的标签。

在实际应用中，我们通过样本数据集来估计真实概率分布 $P(X, Y_t)$，并根据模型的预测结果来逼近真实的标签 $Y_t$ 的分布。因此，在训练过程中，我们使用的是已知的真实标签进行模型的训练和参数优化，而在测试或预测阶段，我们利用学习到的模型对未知数据进行预测，并得到预测的结果 $\hat{Y}$。

总结起来，统计学习中的 $P(X, Y_t)$ 表示的是真实的标签分布，而预测的结果 $\hat{Y}$ 是通过学习到的模型对未知数据进行的预测。

# 实现统计学习的方法

实现统计学习方法的步骤如下：

（1）得到一个有限的训练数据集合；

（2）确定包含所有可能的[[1-3统计学习方法三要素#模型|模型]]的假设空间，即学习[[1-3统计学习方法三要素#模型|模型]]的集合；

（3）确定模型选择的准则，即学习的策略；

（4）实现求解最优[[1-3统计学习方法三要素#模型|模型]]的算法，即学习的算法；

（5）通过学习方法选择最优[[1-3统计学习方法三要素#模型|模型]]；

（6）利用学习的最优[[1-3统计学习方法三要素#模型|模型]]对新数据进行预测或分析。


# 模型

统计学习中, 计算机最终学到的就是`数据间的关系`, 而`数据间的关系`用`模型`表示. 模型属于由`输入空间`到`输出空间`的映射的集合, 这个集合就是`假设空间`. ^ab5e7d

在统计学习中，`模型`（model）是指用来描述数据之间关系的数学模型或函数模型。它是从数据中学习到的，可以用来对新数据进行预测、分类、聚类、降维等任务。

具体来说，`模型`是由输入变量和输出变量之间的关系所组成的，可以是线性的、非线性的、概率的、非概率的等不同类型的模型。例如，线性回归模型、逻辑回归模型、支持向量机模型、决策树模型、神经网络模型等都是常见的模型。

在统计学习中，模型的目标是从数据中学习到一个能够描述数据之间关系的模型，使得该模型能够对新数据进行预测、分类、聚类、降维等任务。模型学习的过程通常包括模型选择、模型拟合和模型评估等步骤，其中模型选择是指从不同类型的模型中选择最合适的模型，模型拟合是指利用数据来调整模型的参数，模型评估是指评估模型的精度和泛化能力等性能指标。

因此，在统计学习中，<mark style="background: #FFB8EBA6;">模型是一个非常重要的概念，它是从数据中学习到的，用来描述数据之间的关系，并用于对新数据进行预测、分类、聚类、降维等任务。</mark>

# 样本与样本点

监督学习中, 训练数据集$T$如下所示

$$T= \left\{(x_1,y_1),(x_2,y_2),(x_3,y_3),\cdots,(x_N,y_N) \right\} $$
其中$(x_i,y_i),i=1,2,\cdots,N$,被称作样本或样本点


# 隐式结构空间

一个隐式结构空间的例子是：文本数据中的主题空间。在文本数据中，每个文档都包含一些单词，而每个单词都有一个概率分布，表示该单词在文档中的出现概率。我们无法直接观测到文本数据的主题，但可以通过主题模型等无监督学习方法来发现文本数据中的主题空间。主题模型可以将文本数据中的单词分成若干个主题，使得同一主题内的单词具有较高的相关性，不同主题之间的相关性较低。通过发现文本数据中的隐式主题结构空间，我们可以更好地理解文本数据中的信息，例如，对文本数据进行分类、聚类、推荐等任务。

# 强化学习

强化学习是一种机器学习的分支，它是一种通过`与环境交互`来学习最优行为策略的学习方式。因此，强化学习可以被视为一系列机器学习过程，其中每个过程都涉及到智能体（agent）与环境之间的交互。

在强化学习中，智能体会执行一系列动作，然后根据环境给出的奖励信号来更新策略，<mark style="background: #FFF3A3A6;">以便在未来的交互中获得更大的奖励</mark>。与监督学习不同，强化学习中的奖励信号不是事先给定的，而是由环境根据智能体执行的动作决定的。因此，强化学习需要智能体具有一定的探索能力，以便在不断的交互中发现最优的行为策略。

总之，强化学习是一种通过与环境交互来学习最优行为策略的机器学习方式，它可以被视为一系列机器学习过程，其中每个过程都涉及到智能体与环境之间的交互。

`AlphaGo`是一个著名的`强化学习`实例。AlphaGo是由DeepMind开发的一个人工智能程序，它在围棋中击败了世界冠军李世石。AlphaGo使用了深度强化学习算法，包括深度神经网络和蒙特卡罗树搜索算法，来学习围棋中的最优策略。

具体来说，AlphaGo使用了两个神经网络：一个策略网络和一个价值网络。策略网络用于预测下一步最可能的落子位置，而价值网络用于评估当前棋局的优劣。AlphaGo还使用了蒙特卡罗树搜索算法来搜索可能的落子位置，并使用策略网络和价值网络来评估每个落子位置的潜在价值。

AlphaGo的训练过程是通过与其他围棋程序进行自我对弈来进行的。在自我对弈中，AlphaGo会根据当前模型选择最优策略，并与自己下棋，然后使用胜利或失败的结果来更新模型。通过不断的自我对弈和模型更新，AlphaGo最终学习到了围棋中的最优策略，从而击败了世界冠军李世石。

总之，AlphaGo是一个强化学习的实例，它使用了深度神经网络和蒙特卡罗树搜索算法来学习围棋中的最优策略，并通过自我对弈和模型更新来不断提高自己的水平。

# 监督学习, 无监督学习, 强化学习, 深度学习与机器学习

这几个"学习"的关系如下图所示

除机器学习外, 其他几个"学习"的关系并不准确, 因为"学习"可能存在交叉

```tikz
\begin{document}
\begin{tikzpicture}
	\node[rounded corners, shape=rectangle, draw] (ML) at (-2,-1) {Machine Learning};
	\node[rounded corners, shape=rectangle, draw] (DL) at (5,2) {Deep Learning};
	\node[rounded corners, shape=rectangle, draw] (RL) at (5,0) {Reinforcement Learning};
	\node[rounded corners, shape=rectangle, draw] (SL) at (5,-2) {Supervised Learning};
	\node[rounded corners, shape=rectangle, draw] (UL) at (5,-4) {Unsupervised Learning};
	\draw[->] (ML) -- (0,-1) |- (DL);
	\draw[->] (ML) -- (0,-1) |- (RL);
	\draw[->] (ML) -- (0,-1) |- (SL);
	\draw[->] (ML) -- (0,-1) |- (UL);
\end{tikzpicture}
\end{document}
```
机器学习是一个较大的分类, 其下有`深度学习`,`强化学习`,`监督学习`,`无监督学习`几个分支,

`强化学习`强调只能系统与环境的交互, AlphaGo就是一个著名的强化学习例子

`深度学习`一般通过神经网络实现

`监督学习`一般指需要标注好的数据集作为输入进行学习

`无监督学习`无监督学习相反, 它不需要标注好的数据集作为输入


# 欧氏空间

## 什么是欧氏空间

欧氏空间，也称为欧几里得空间，是一种常见的数学概念，用于描述我们熟悉的物理空间中的几何性质。在欧氏空间中，可以定义距离、角度和向量等概念，并进行相应的运算。

具体来说，欧氏空间是一个由点和向量组成的集合，其中每个点由一组实数坐标表示，每个向量由起点和终点之间的差表示。欧氏空间中的点和向量可以具有任意的维度，例如二维平面、三维空间，甚至更高维度的空间。

在欧氏空间中，可以使用距离公式（欧几里得距离）来衡量两个点之间的距离，它是通过计算点之间坐标差的平方和的平方根得到的。这种距离度量在实际应用中非常常见，例如计算两点之间的直线距离。

欧氏空间还具有向量的运算规则，包括向量的加法、减法和数量乘法。这些运算使得我们可以对向量进行组合和变换，从而进行向量的线性组合、内积、外积等操作。

在统计学、机器学习和数据分析等领域，欧氏空间经常用于表示特征空间或样本空间，以及定义模型和算法的数学基础。通过在欧氏空间中进行距离度量、向量运算和几何推理，我们可以进行模式识别、聚类分析、回归分析等任务，从而对数据进行分析和建模。

## 欧式空间与n维坐标系

欧式空间可以**理解**为常说的n维坐标系。在欧式空间中，可以使用n个坐标轴来表示点的位置，每个坐标轴对应空间的一个维度。例如，在二维欧式空间中，我们使用x轴和y轴表示平面上的点的位置；在三维欧式空间中，我们使用x轴、y轴和z轴表示空间中的点的位置。更一般地，n维欧式空间可以通过n个坐标轴表示。

在欧式空间中，可以定义距离和角度等几何概念，以及向量的加法和数量乘法等运算。因此，欧式空间是一种常用的数学工具，用于描述和分析几何结构、向量空间、线性代数等问题。在统计学习中，欧式空间常用于表示特征向量和数据点的空间，以及定义损失函数和模型参数的优化问题。

# 极大似然估计

https://www.bilibili.com/video/BV1Hb4y1m7rE

# 过拟合


# RGB-D显著性物体检测

*"基于RGB-D（RGB-depth）的显著性物体检测"* 是一种利用<mark style="background: #FFB8EBA6;">RGB图像</mark>和<mark style="background: #FFB8EBA6;">图像中的透视、遮挡关系</mark>的信息来识别和突出显示图像中最显著或最引人注目的物体的方法。

# 多任务学习

理解以下句子

> 模型解空间优化通过对 RGB 和 `RGB-D 显著性物体检测`这两种任务进行`多任务学习`,并采用`模型参数共享`的方式约束模型的解空间,从而将额外的 RGB 显著性物体检测任务学习到的`知识迁移`至 RGB-D 显著性物体检测任务中。

- 多任务学习
	- 一种机器学习方法
	- 目标是同时训练一个模型来执行多个相关的任务。
	- 举例解释: 在上面的句子中，提到了两个任务：RGB 显著性物体检测和 RGB-D 显著性物体检测。这两个任务都涉及到在图像中识别物体的显著性（也就是物体在图像中引人注目的程度）。多任务学习的想法是，通过同时训练模型执行这两个任务，可以让模型更好地理解图像中物体的显著性。


# 模态

可以理解为<mark style="background: #FFB8EBA6;">对同一个事物的不同描述,</mark> 如想要描述一个蜜蜂, 可以描述它的声音、飞行的姿态、所处地点、红外图像等不同的信息

在计算机科学和信息学领域，"模态" 通常用来表示一种特定的数据类型、表示方式或信息来源。在跨模态问题中，我们关注的是不同的数据类型或信息来源。

举个例子，图像领域常常涉及到多种模态的数据，包括：

1. **RGB 模态：** 这是常见的彩色图像模态，由红色 (R)、绿色 (G) 和蓝色 (B) 通道组成。
    
2. **深度模态：** 这种模态包含了每个像素的深度信息，通常以灰度图像的形式表示，用于捕捉场景中物体到相机的距离。
    
3. **红外模态：** 这是一种热成像模态，用于检测物体的热分布，通常与可见光图像不同。
    
4. **声音模态：** 在音频处理领域，声音数据是一种模态，通常以波形或频谱图的形式表示。
    

跨模态任务通常涉及到将来自不同模态的数据进行关联、融合或匹配。这可以包括跨模态检索、跨模态识别、跨模态生成等任务，其中目标是从不同的模态数据中获得有意义的信息或进行相关性分析。因此，"模态" 在这些任务中用来描述不同的数据来源或类型。

# 自监督学习

自监督学习和无监督学习是两种不同的机器学习范式，它们在学习方式和目标上有一些区别：

1. **监督信号的存在与否**：
    
    - **自监督学习**：在自监督学习中，模型从未标记的数据中学习，但它利用数据本身内在的结构或关系来生成伪标签。模型的目标是预测这些伪标签。自监督学习通常使用输入数据的某种变换或者数据本身的局部信息来产生伪标签。
    - **无监督学习**：无监督学习模型从未标记的数据中学习，但不依赖于自动生成伪标签。它的目标通常是发现数据中的模式、结构、聚类或降维等信息，而无需明确的监督信号。
2. **学习的方式**：
    
    - **自监督学习**：自监督学习的方法通常通过将输入数据转换为某种形式的表示，然后再从这个表示中恢复原始输入，以让模型学习有用的特征。这个过程中，模型自动生成了训练标签（伪标签）。
    - **无监督学习**：无监督学习的方法通常不会生成伪标签。它可以是一种数据建模的方式，例如生成模型或聚类方法，用于描述数据的分布或聚类结构。
3. **应用领域**：
    
    - **自监督学习**：自监督学习在计算机视觉、自然语言处理和语音处理等领域得到广泛应用，用于学习有用的表示或特征。
    - **无监督学习**：无监督学习方法可以用于聚类、降维、密度估计等各种领域，不限于特定应用。

总的来说，自监督学习是无监督学习的一个特例，其中模型通过自动生成伪标签来引导学习。无监督学习是一个更广泛的范畴，包括各种无监督学习任务，而自监督学习是其中的一种方法。

# 语义分割

根据图像的语义为其每个像素分配类别标签


# 图像的低层特征与高层特征

- 低层特征:指图像中的基本、原始信息，通常是从像素级别提取的。这些特征通常包括颜色、亮度、纹理、边缘、形状和方向等。低层特征对应于图像中的局部信息，通常不具备高度语义。
    
- 高层特征:具有更高的语义含义。它们通常表示图像中的物体、场景或对象的特性，比如检测到一个人脸、一只猫或一辆汽车。

# 正则化

机器学习中减少过拟合的一个过程

# 过拟合

在已有数据集上效果好, 但再其他数据上效果差

# 超参数

1. 超参数的“学院派”定义：

> 在机器学习的过程中，  
> 超参= 在开始机器学习之前，就人为设置好的参数。  
> 模型参数=通过训练得到的参数数据。  
> 通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果

2. 怎么决定超参数？

> 1. 定义关于模型的更高层次的概念，如复杂性或学习能力。  
> 2. 不能直接从标准模型培训过程中的数据中学习，需要预先定义。  
> 3. 可以通过设置不同的值，训练不同的模型和选择更好的测试值来决定

3. 超参数的“通俗”定义：

> 超参数也是一种参数，它具有参数的特性，比如未知，也就是它不是一个已知常量。  
> 是一种手工可配置的设置，需要为它根据已有或现有的经验，指定“正确”的值，也就是人为为它设定一个值，它不是通过系统学习得到的。

4. 超参数的一些示例：

> 1. 聚类中类的个数  
> 2. 话题模型中话题的数量  
> 3. 模型的学习率  
> 4. 深层神经网络隐藏层数  
> 5.树的数量或树的深度  
> 6. 矩阵分解中潜在因素的数量  
> 7. k均值聚类中的簇数


# 元学习

# 归一化层


# 具身智能系统

指能够理解、推理与物理世界进行交互的智能系统