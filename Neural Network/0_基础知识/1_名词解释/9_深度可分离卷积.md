
>[!warning] 提示
>点击右上角「书本」![[Pasted image 20231125105318.png]]图标, 进入阅读模式, 以获得更好的阅读体验！

>[!tips] 声明
>本笔记转载自[知乎_# 深度可分离卷积](https://zhuanlan.zhihu.com/p/92134485), 结合了 ChatGPT 的回答

# GhatGPT 的回答

- Q：这段文字中, 深度可分离卷积是什么意思, 这是否是一个为人所熟知的概念？Each one of our kernel predictors K in Fig. 2 is a simple convolutional network whose input is the style descriptor W, while the output is a depthwise-separable kernel.
- 深度可分离卷积是一个常见的卷积神经网络中的概念。它是一种卷积操作的变体，旨在减少模型的参数量和计算量，同时保持良好的性能。深度可分离卷积分为两个步骤：深度卷积（depthwise convolution）和逐点卷积（pointwise convolution）。
	- 深度卷积：在深度卷积中，对输入的每个通道（channel）应用一个独立的卷积核。这意味着如果输入数据有 n 个通道，那么将会有 n 个独立的卷积操作。每个通道的卷积核都只与该通道中的数据进行卷积操作，而不涉及其他通道的数据。这一步骤可以有效地捕获输入数据中的空间特征。
	- 逐点卷积：在逐点卷积中，对深度卷积的输出应用一个 1 x 1 的卷积核。这个卷积核与整个深度卷积的输出进行卷积操作，但是每次只对一个像素点进行操作。这一步骤的目的是将深度卷积的输出转换为新的特征表示，从而改变特征的维度和通道数量。
	- 深度可分离卷积通常用于轻量级模型或者对计算资源有限的场景中，因为它可以减少模型的参数数量和计算量，同时保持模型的性能。在给定的上下文中，描述器 K 的输出是一个深度可分离的卷积核，意味着这个卷积核是通过深度可分离卷积操作得到的，而不是传统的全连接或标准卷积操作。这种操作通常被用于图像处理任务中，尤其是在风格转移等任务中。

# 知乎_深度可分离卷积

一些轻量级的网络，如 mobilenet 中，会有深度可分离卷积 depthwise separable convolution，由 depthwise(DW)和 pointwise(PW)两个部分结合起来，用来提取特征 feature map

相比常规的卷积操作，其参数数量和运算成本比较低

## 常规卷积操作

对于一张5×5像素、三通道（shape 为5×5×3），经过3×3卷积核的卷积层（假设输出通道数为4，则卷积核 shape 为3×3×3×4，最终输出4个 Feature Map，如果有 same padding 则尺寸与输入层相同（5×5），如果没有则为尺寸变为3×3

![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240417104412.png)

卷积层共4个 Filter，每个 Filter 包含了3个 Kernel，每个 Kernel 的大小为3×3。因此卷积层的参数数量可以用如下公式来计算：

N_std = 4 × 3 × 3 × 3 = 108

## 深度可分离卷积

- 逐通道卷积

Depthwise Convolution的一个卷积核负责一个通道，一个通道只被一个卷积核卷积

一张5×5像素、三通道彩色输入图片（shape 为5×5×3），Depthwise Convolution 首先经过第一次卷积运算，DW 完全是在二维平面内进行。卷积核的数量与上一层的通道数相同（通道和卷积核一一对应）。所以一个三通道的图像经过运算后生成了3个 Feature map(如果有 same padding 则尺寸与输入层相同为5×5)，如下图所示。

![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240417104430.png)

其中一个 Filter 只包含一个大小为3×3的 Kernel，卷积部分的参数个数计算如下：

N_depthwise = 3 × 3 × 3 = 27

Depthwise Convolution完成后的Feature map数量与输入层的通道数相同，无法扩展Feature map。而且这种运算对输入层的每个通道独立进行卷积运算，没有有效的利用不同通道在相同空间位置上的feature信息。因此需要Pointwise Convolution来将这些Feature map进行组合生成新的Feature map

- 逐点卷积

Pointwise Convolution 的运算与常规卷积运算非常相似，它的卷积核的尺寸为 1×1×M，M 为上一层的通道数。所以这里的卷积运算会将上一步的 map 在深度方向上进行加权组合，生成新的 Feature map。有几个卷积核就有几个输出 Feature map

![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240417104447.png)

由于采用的是1×1卷积的方式，此步中卷积涉及到的参数个数可以计算为：

N_pointwise = 1 × 1 × 3 × 4 = 12

经过Pointwise Convolution之后，同样输出了4张Feature map，与常规卷积的输出维度相同

## **参数对比**

回顾一下，常规卷积的参数个数为：  
N_std = 4 × 3 × 3 × 3 = 108

Separable Convolution的参数由两部分相加得到：  
N_depthwise = 3 × 3 × 3 = 27  
N_pointwise = 1 × 1 × 3 × 4 = 12  
N_separable = N_depthwise + N_pointwise = 39

相同的输入，同样是得到4张Feature map，Separable Convolution的参数个数是常规卷积的约1/3。因此，在参数量相同的前提下，采用Separable Convolution的神经网络层数可以做的更深。