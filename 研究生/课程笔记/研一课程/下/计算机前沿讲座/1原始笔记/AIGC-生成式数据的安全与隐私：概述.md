
## 主讲人

张玉书, 南京航空航天大学, 计算机科学与技术学院

生成式人工智能相关

## 前言

AIGC, 是生成式人工智能的缩写

生成式数据的安全与隐私

生成数据的隐私行可控性真实性与可控性与合规性

## AIGC 的概念

AI-Generated Content 为人工智能生成内容

AIGC 的发展是与人工智能的发展伴随的

1. 早期萌芽阶段： 20 世纪 50 年代到 90 年代中期
2. 沉淀积累期： 20 世纪 90 年代中期到 21 世纪 10 年代中期
3. 快速发展阶段： 21 世纪 10 年代中期至今

AIGC 日渐实用化, 文本生成如 ChatGPT, 图像生成如 midjpurney

## 生成式数据的安全和隐私问题

- 语言模型中可能生成人的个人隐私, 图像生成可能侵犯人的肖象权
- 合规性与合法性：生成式数据也会包含毒性和反事实内容

 在生成式数据的安全性问题时, 我们不应该仅仅看生成模型, 也应该看看生成数据流程中的其他过程, 如数据收集问题. 用于训练的许多数据可能都是有问题的.

## 生成式数据-隐私性

### AIGC 内生隐私

生成式数据模型训练数据的分布, 因此可能噪声敏感数据的复现

如模型遗忘, 如果生成一些带有敏感信息的数据, 则将其丢掉

如数据集修改, 如果数据集中涉及隐私, 则尽量少的使用这个数据集

### AIGC 助力隐私
 
 生成式数据可以去除生成式数据的问题, 代替侵犯隐私的生成式数据

如对人脸进行修改后,  人类无法识别修改后照片中人的身份, 但机器可以识别. 将 A 修改为 B, 人在识别修改后图像时, 会将修改后图像中的人识别为 B, 但机器依旧识别为 A.

## 生成式数据-可控性

代表工作：

1. 阻止 GAN 模型对预期生成结果的访问
	1. 阻止 GAN 对其生成图像 A 直接访问
	2. 而是对 GAN 生成的图像 A 添加一个扰动后, 再给 GAN 模型访问
2. 允许对生成的原始结果访问, 但这些原始结果是可追溯的, 如加入水印等
	1. 如：在训练集中植入水印, 生成的结果中也具有水印, 从而达成可追溯性
		1. 音色水印
		2. 稳定性水印
		3. ……
		4. 基于区块链的水印
			1. 虽然投入比较大, 但是面临问题时, 比较能祈祷保障作用

## 生成式数据-真实性

### 生成式检测：他们是否是生成的

1. 基于 GAN 生成的图像中存在较大的伪影
2. DM 生成的图像通过源模型生成后的图像误差比真实图像小
3. 探索真实数据的不变性：通过找到真实图像的
4. 根据概率曲率不同来判断
5. 人类的文字更发散, 而机器的更集中, 可以通过这种方法来判断是否是生成的

### 生成式归因：是哪种模型生成的

1. 不同扩散模型具有不同的指纹, 构建一个多分类器来区分生成式数据由哪种模型生成
2. 概念归因, 可将生成图像归音于其训练数据的概念, 概念指风格、艺术家等

## 生成式数据-合规性

### 无毒性

- 无毒的训练数据集是确保生成安全数据的关键, 一些工作在专研这个方面的工作
- 引导模型不生成有毒的生成式数据 (裸体、抢劫等)
- 概念删除, 如删除性别偏见等

### 事实性

1. 对于用户的提问, 用多个自动对话机器人进行辩论, 结论统一后再回馈给用户
2. 其他工作

## 总结

### 可能的研究方向

1. 可证明的机器/概念遗忘：虽然有实验与现象说明机器可能会有遗忘问题, 但是如何证明？
2. 生成式数据的篡改检测：生成式数据也会遭受恶意篡改, 由于其本身是由 AIGC 生成的, 当面临 AIGC 的篡改时, 这样的篡改检测可能和比较困难
3. 基于真实数据不变性的生成式检测：现有的生成式检测关注生成式数据的变量 (如伪影、模型指纹等), 但这些会随着模型的发展而变化. 相反, 真实数据的分局具有文件性, 但少有工作基于此做检测
4. 隐藏毒性的检测：在 AIGC 的帮助下, 攻击者可以将有毒信息以难以察觉的生成式的数据 (恶意概念)中, 这样使得有毒信息容易逃避现有的检测技术
5. 合规性的机器评估：尽管
