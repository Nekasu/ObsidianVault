
>[!warning] 提示
>点击右上角「书本」![[Pasted image 20231125105318.png]]图标, 进入阅读模式, 以获得更好的阅读体验！

YTB是youtube的缩写

## 介绍一些 YTB CDN (Content Ditribution Network)的组件

每个缓存服务器, 都配备了 cache、SSD 或 HDD 作为数据存储, 用于存储视频数据,

![|396](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423111946.png)

当请求被发送到这个边缘服务器上时, 将从缓存中获取视频数据. 如果缓存中没有对应的数据, 则将从 SSD 或 HDD 中查找对应的视频数据. 

如果 SSD 或 HDD 中依旧没有对应的数据时, 云端服务器将是最后的选择.

![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112216.png)

## 缓存的重要性

我们考虑缓存的重要性. 缓存作为第一级的存储结构, 如果一个缓存调度算法 (eviction algorithm)足够优秀, 那么他将降低后续的流量消耗.

我们的评价指标是 P95 的 miss ratio, 选择 95 而非其他数值是因为根据实验, 95%是一个“瓶颈”

## 近期的一些基于机器学习的调度算法

有效, 但有三个问题
1. ML 的资源消耗
	1. 举例说明了 ML 算法的资源消耗
	2. ![|396](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112146.png)
2. 健壮性 (robust)问题 
	1. 理论下限低
3. 在实际的噪声下, 比较一个新的调度算法是较为困难的 ^e45d6c
	1. 一般使用 A/B 测试
		1. 为了介绍 A/B 测试, 先介绍了 ytb 的边缘设备集群
			1. Ytb 的边缘设备集群包含多个机架(Racks)
				1. ![|151](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112315.png)
			2. 每个机架包含多个结构相同或类似的服务器
				1. ![|151](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112403.png)
				2. 因此将同一个机架上的服务器进行比较是合理的, 
				3. 因为他们具有相同的软硬件架构与设置
				4. 同时他们收到的请求也是类似的
		2. 在一个机架上, 
			1. 我们一个机器作为实验组, 上面运行新的调度算法(图中exp)
			2. 设置另一个机器作为对照组, 上面运行旧的调度算法(图中ctrl)
				1. ![|142](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112546.png)
			3. 用实验组上观测到的 miss ratio 除以对照组上的观测到的 miss rotia, 当作该机架的测试样本 (measurement sample)
				1. ![|344](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112627.png)
		3. 从多个机架上获取不同的测试样本 (measurement sample), 用于拟合影响分布 (impact distribution)
			1. ![|422](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112659.png)
	2. 但是, 在现实中, 由于不同的负载, 一个机器 (指的是服务器 server)的行为不可能完全相同

## 解决上述三个问题的方法, 即本文的方法：HALP 与 impact analisys

HALP用于解决前面两个问题, impact distribution analisys用于解决第三个问题

![|422](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112729.png)

### HALP

HALP 将用于解决前两个问题, 即：
1. 机器学习 ML 的资源消耗问题.
2. 机器学习的健壮性差的问题.
3. 如下图所示
	1. ![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423112808.png)

#### 介绍启发式方法与 ML 方法的优点与缺陷, 从而引出 HALP

1. ML 的优点与缺点
	1. 优点：效果好, low miss ratio
	2. 缺点：资源占用大
2. 启发式算法的优点与缺点
	1. 优点：资源占用小, high miss ratio
	2. 缺点：效果较差
3. HALP 的想法
	1. 结合两个这优点
	2. 许多选择将首先被启发式算法排除掉, 从而选出一些最可能的调出数据块, 作为候选data
		1. 以 LRU 算法为例
	3. 候选 data 再输入神经网络, 判断结果

#### HALP 的核心

1. HALP 的核心由两个部分组成
	1. 启发式算法
		1. ![|108](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423113100.png)
	2. 基于损失函数的神经网络
		1. ![|165](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423113121.png)
		2. 其输入为：单个候选调出数据块的特征 (feature)
		3. 其输出为：一个实数值, 用于判断输入候选调出数据快被再次访问的概率的大小

#### 调换的发生过程/驱逐策略的执行

1. 一个启发式算法给出一组 (set)的候选调出数据块, 如下图所示 
	1. ![|235](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423113209.png)
	2. 一组中, 候选调出数据块的数量是一个超参数
		1. 如果太高, 将影响整体算法的计算性能
		2. 如果太低, 可能无法得出准确的结果
		3. 发现数量 4 是一个不错的
3. 当选出候选调出数据块组后, 这个基于神经网络的模型将对该组中所有的候选数据块进行排序, 并选出最终的调出数据块
	1. ![|427](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423113355.png)
	2. 最终调出数据块的选择(即Eviction Desicion, 图中右侧红框处)是通过一个“锦标赛”角逐出的
		1. 该“锦标赛”包含 3 组一对一的比赛
	3. 解释为何使用分数代表可能再次被访问的概率, 而非直接预测该数据块下次被访问时间间隔的原因
		1. 使用分数可以用于排序, 而排序更符合最终的目的：选出一个最合适的调出数据块
	4. 在选出合适的调出块后, 候选调出数据块组中的其他候选调出块将被放回启发式算法中

#### 在线训练过程与训练数据的获取

上述“锦标赛”也可用于生成深度学习所需的训练数据. 但是训练数据并非是在 ML 模型推测阶段生成的. 

- 在推测阶段, HALP 将保存所有的“锦标赛”三元组, 如 $(c_1, c_2, ?)$. 这些“锦标赛”三元组将被当作是训练样本, 如下图红框中所示
	- ![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423113739.png)
	- 该三元组中, 前两位表示正在“比试”的两个数据块, 最后以为表示比试的结果
		- 比赛结果是一位二进制数, 用于表示 $c_1、c_2$中谁在未来将被先访问.
	- 方便起见, 
		- 我将三元组中的第一位叫作一号参赛者, 
		- 第二位叫作二号参赛者, 
		- 第三位叫作比赛结果.
	- 该锦标赛的结果 (第三位)在推测阶段暂不赋值
		- 因此, 表示锦标赛$(c_1, c2, ?)$的快照将被保存
			- 由于该锦标赛的结果为“?”, 所以该训练样本此刻是一个尚未有“label”的训练样本
	- 锦标赛的结果/训练数据获取label
		- 在某时刻, 如果锦标赛的某一参赛者被请求调用, 则直接得出所有与该参赛者相关的锦标赛的结果
			- 如果一号参赛者$(c_1)$被调用, 则与 $c_1$ 相关的所有锦标赛三元组$(c_1 ,c_k, ?)$将立刻变为$(c_1 ,c_k, 1)$, 表示$c_1$将更可能在以后被调用
			- 如果二号参赛者$(c_k)$被调用, 则锦标赛三元组$(c_1 ,c_k, ?)$将立刻变为$(c_1 ,c_k, ?)$, 表示 $c_2$ 将更可能在以后被调用
			- 此处标签位的 1 表示一号参赛者获胜, 0 表示一号参赛者失败
			- 上述获取label的过程如下图红所示
				- ![|448](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423113911.png)
		- 这些得到结果的锦标赛结果就是训练数据
			- 用一个队列存储这些训练数据, 当训练数据达到1024条时, 将对神经网络进行一次训练

#### 网络模型与特性

1. 网络模型
	1. 使用一个两层的多层感知机作为神经网络
2. 特性
	1. 模型特性
		1. 进行一次预测需要 720 ns
		2. 一次训练的时间为毫秒级
		3. 损失函数：交叉熵损失函数
	2. 用于表示$c_1$的特征数据 (同一视频的特征数据), 如下图所示
		1. 如下图所示
			1. ![|474](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114003.png)
		2. 对于上图的解读如下：
			1. 基于到达时间的特征数据
				1. 到达间隔时间 (time between acceses) ：用于表示短期内, 该视频被用户请求的频率
				2. 指数衰减计数器(Exponential decay counters )：用于表示长期下, 该视频被用户请求的频率
				3. 平均请求时间(average time between accesses)：用于表示该视频平均多长时间被用户请求一次
				4. 未被请求时间(time since last access)：该视频距离上次请求经过了多长的时间
			2. 基于视频特征的特征数据
				1.  数据块的末尾地址(End of Chunk)：由于视频的播放是连续的, 所以对于视频数据的请求也是连续的. 
					2. 如果某用户请求的数据块是他请求的最后一个数据块, 那么该数据块被再次请求的可能性, 与其他数据块比较来说, 更低

### 从测量值与噪声中获取「影响分布Impact Ditribution」

- 该部分的核心问题为：将算法影响与噪声影响结合(marrying the algorithm impact and nosie impact)
	- 此处的算法影响(algorithm impact)指的应该就是由[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#测量拟合Measurement Fit|测量拟合(Measurement Fit)]]得到的分布
	- 此处的噪声影响(nosie impact)指的就是由[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#测量拟合Measurement Fit|测量拟合(Measurement Fit)]]得到的分布

#### 测量拟合Measurement Fit
	
1. 本文将[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#^e45d6c|上述A/B测试]]中得到的数据称作“测量拟合(measurement fit)”

#### 噪声拟合Noise Fit

噪声拟合可以用下图表示：

![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114203.png)

1. 为了消除噪声的影响, 我们设置了除“实验组”、“对照组”外的第三台机器, 称作“无操作组”(图中蓝色方块).
	1. 无操作组使用基础的启发式算法(baseline algorithm)
	2. 无操作组与对照组都是使用的baseline启发式算法, 区别何在？
		1. 在现实中, 由于不同的负载, 一个机器 (指的是服务器 server)的行为不可能完全相同
		2. 由于无操作组与对照组为不同的机器(server), 但二者使用的是相同的缓存调度算法.
		3. 因此从二者中获得的观测数据会因为他们是同一机架上的不同服务器而不同.
		4. 这之间的差异被文章认为是“噪声”
2. 用无操作组上观测到的 miss ratio 除以对照组上的观测到的 miss rotia, 当作该机架的噪声样本 (noise sample)
	1. 对应图中蓝色箭头与Noise1, Noise n等蓝色字样
		1. ![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114356.png)
	2. 图中右侧图表上的蓝色曲线代表噪声分布
		1. ![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114524.png)
3. 从多个机架上获取不同的噪声样本 (noise sample), 用于拟合噪声分布 (noise distribution)

#### 真实影响分布拟合(True Impact Distribution Fit)

1. 由于「[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#测量拟合Measurement Fit|测量拟合(Measurement Fit)]]得到的分布」中包含了「[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#噪声拟合Noise Fit|噪声拟合(Noise Fit)]]得到的分布」, 所以「[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#测量拟合Measurement Fit|测量拟合(Measurement Fit)]]得到的分布」并不是「真实影响分布(True Impact Distribution)」
2. 为了获得真实影响分布(True Impact Distribution), 本文选择使用极大似然估计进行计算, 最终得到下图中绿色曲线, 为真实影响分布(True Impact Distribution)
	1. ![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114705.png)
	2. 右侧图像的横坐标是
		1. exp/ctrl, 

## 评估(Evaluation)

### 关于评估的设置(Evalution Setup)

1. 实施环境：使用谷歌 SmartChoice 机器学习服务(Google's SmartChoice ML service)
2. 关于评估的三个问题
	1. HALP可以没有回归(regression)的前提下, 有更低的未命中率(less byte miss ratio)吗？
	2. HALP的计算资源占用怎样？
	3. HALP与SOTA(State of art)的缓存调度算法相比, 结果怎样？
3. 评估指标
	1. 未命中率(miss Ratio)
4. 评估方法
	1. 影响分布分析(impact distribution analysis)
		1. 影响分布即为[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#真实影响分布拟合(True Impact Distribution Fit)|真实影响分布]]

### 问题1的回答：可以

- HALP健壮的(robustly)提升了 9.1% 的P95
	- 介绍橙色曲线：是「[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#测量拟合Measurement Fit|测量拟合(Measurement Fit)]]得到的分布」
	- 介绍蓝色曲线：是「[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#噪声拟合Noise Fit|噪声拟合(Noise Fit)]]得到的分布」
	- 介绍绿色曲线：是[[高级计算机网络汇报_杨欢_张轩豪_周肖桐#真实影响分布拟合(True Impact Distribution Fit)|真实影响分布]]
	- 如下图所示
		- ![|422](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114756.png)

### 问题2的回答：还可以

1. 最低值更低, 低了约 1.8%, 且方差更小
	1. CPU消耗与请求数量呈线性关系
	2. ![|448](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423114821.png)

### 问题3的回答：比他们好

1. 与SOTA的启发式方法相比
	1. 本文的P95字节未命中率低了 7%, 如图中蓝绿曲线所示, 蓝色曲线代表本文方法HALP, 绿色曲线代表SOTA的启发式方法
		1. ![|448](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423115123.png)
2. 与SOTA的机器学习(LRB)相比
	1. P95 未命中率的值相近
	2. 但本文方法具有更低的资源消耗
	3. 如下图红蓝曲线所示, 蓝色曲线代表本文方法HALP, 红色曲线代表SOTA的机器学习方法LRB
		1. ![448](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240423115123.png)

因此, 结合 P95字节未命中率与 CPU资源占用来看, 本文的方法比SOTA方法更好.

## 总结 

1. 提升了9.1%的 P95 字节未命中率(byte miss ratio), 且并不会比启发式算法更差
2. 核心在于将「启发式算法」与「机器学习」结合
3. 已经在2022年应用于 ytb