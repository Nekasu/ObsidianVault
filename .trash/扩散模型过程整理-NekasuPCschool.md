
>[!warning] 提示
>点击右上角「书本」![[Pasted image 20231125105318.png]]图标, 进入阅读模式, 以获得更好的阅读体验！

## 扩散模型的前提

1. 扩散模型遵循这样一个前提：所有图像都满足某种特定的概率分布
	1. 高斯噪声服从高斯分布, 且高斯噪声是从高斯分布中采样得到的图像
	2. 复杂图像服从复杂分布, 且复杂图像是从某个复杂分布中采样得到的图像
3. 如何将复杂分布变成高斯分布, 就是扩散过程需要完成的任务.
	1. 实际上, 这一步很简单
	2. 在实际中i, 我们往往是有一张特定的图像, 只需要往里面加高斯噪声就可以达成这个目标
	3. 这是因为这个特定的图像可以看作是一个定值, 所以可以看作是高斯噪声的均值
4. 如何将高斯分布变换成其他复杂分布, 就是逆扩散过程需要完成的任务
	1. 

## 扩散是什么过程

一个预测噪声的模型, 将标准高斯噪声中的噪声一点一点去除的过程

## 训练数据的获取

## 推理过程的流程

## 网络核心是什么

# 介绍当前的图像生成模型的共同目标

1. 输入一个自高斯分布中获取的噪声图像
2. 经过神经网络的操作, 使噪声图像变成一个其他复杂分布的一个实例
3. 这个实例满足的分布与真实分布越接近越好

## 如何衡量生成图像满足的分布与真实分布的差距？

1. 衡量二者之间的差距之前, 我们先做出这样一个假设
	1. 假设我们知道生成模型生成图像满足的分布 $P_{\theta}(X)$
		1. 其中 $X$ 为随机变量
		2. $\theta$ 表示生成模型的参数
2. 其次, 我们定义一些符号
	1.  我们定义真实图像的数据集为 $data$
		1. 从真实数据集 $data$ 中可以获取真实图像 $x_1,x_2,x_3\cdots$
3. 在上述符号定义的前提下, 我们可以知道这样一个事实：
	1. 生成图像满足的分布 $P_\theta(X)$ 中, 随机变量 $X$ 的取值为 $x_i, (i=1,2,3,\cdots)$ 的概率可以表示为 $P_\theta(X=x_i)$ 
	2. 而上述概率 $P_\theta(X=x_i)$ 的含义为：生成模型生成的图像与真实图像一模一样的概率
	3. 这个概率越大, 就说明这个模型生成的图像与真实图像越像
4. 所以如果想让模型生成的图像与真实图像越像, 所以应该概率 $P_\theta(X=x_i), i=1,2,3,\cdots$ 都取最大值
5. 也即 $\prod\limits_{i}P_\theta(X=x_i)$ 达到最大值, 也即 $\max \prod\limits_{i}P_\theta(X=x_i)$
6. 实际上, 这个过程就是极大似然估计的过程
7. 从另一层面来说, 上述累乘求最大值的过程化为 KL 散度, KL 散度表示两个分布之间的相似程度, 如果无法理解极大似然估计的过程, 可以利用 KL 散度进行理解
8. 但实际上, 我们无法直接计算 $P_\theta(X=x_i)$, 因为我们无法获取 $P_\theta$ 这个概率分布, 那么我们应如何计算这个概率分布呢？

## 如何计算 $P_\theta(X=x_i)$ 

有如下定义：

$$
P_\theta(X=x_i)=\int\limits_{z_i\sim\mathcal{N}(0,1)} P(Z=z_i)P_\theta(X=x_i | Z=z_i)dz,
$$
其中, 
1.  $z_i$ 为从高斯分布中采样的噪声图像, $x_i$ 为真实图像
2. 等式左侧为 $P_\theta(X=x_i)$, 其含义为模型生成的图像为 $x_i$ 的概率
3. 等式右侧中, 
	1. $P(Z=z_i)$ 表示从标准正态分布中获取噪声图像为 $z_i$ 的概率, 是一个较为容易计算的概率
	2. $P_\theta(X=x_i | Z=z_i)$ 表示将噪声图像 $z_i$ 输入进生成模型中, 模型生成的图像为 $x_i$ 的概率.

我们需要解释一下这个定义

1. 全概率公式
	1. 上述定义实际上全概率公式的一个积分形式
	2. 值得注意的是, 全概率公式中的条件概率 $P_\theta(X=x_i | Z=z_i)$ 与边缘概率 $P(Z=z_i)$ 并不要求满足同一分布。
	3. 相反，全概率公式的一个关键特性就是它允许我们将条件概率与不同的边缘概率结合起来，从而计算总体的边缘概率。这是全概率公式的核心思想所在。
2. 公式的含义
	1. 由于公式左侧无法计算, 所以考虑使用全概率公式计算.
	2. 模型能够生成图像 $x_i$ 的概率, 等于, 从正态分布中获取噪声图像 $z_i$ 的概率 $P(Z=z_i)$ 与模型在输入噪声图像 $z_i$ 的前提下, 生成图像 $x_i$ 的概率 $P_\theta(X=x_i | Z=z_i)$.


由于噪声图像 $z_i$ 是从正态分布中获取的, 所以 $P(Z=z_i)$ 是一个容易计算的值

在这样的化简下, 问题变成了如何计算 $P_\theta(X=x_i | Z=z_i)$ 

## 如何计算 $P_\theta(X=x_i | Z=z_i)$ 

### 一个符合直觉的定义

实际上, 有一个符合直觉的定义如下：

$$
P_\theta(X=x_i|Z=z_i)=\begin{cases}1, \quad G(z_i)=x_i\\
0, \quad G(z_i)\ne x_i\end{cases}
$$

这个式子中, 
-  $G$ 表示神经网络, 
- $z_i$ 表示输入的噪声图像, 
- $G(z_i)$ 表示输入噪声  $z_i$ 的情况下, 网络生成的图像
- $G(z_i)=x_i$ 表示网络生成的图像与真实图像 $x_i$ 完全相同
- $X$ 是表示真实图像的随机变量, $x_i$ 是 $X$ 的取值
	- 每个 $x_i$ 都是真实世界的一张图像

整个式子表示, 如果网络生成的图像与真实图像完全相同, 则概率 $P_\theta(X=x_i | Z=z_i)$ 为 1, 否则为 0

但实际上, 这个定义是很不合理的. 网络生成的图像与真实图像完全相同的可能性很低, 所以如果用这个「符合直觉的定义」进行计算, 得到的 [[扩散模型过程整理#如何计算 $P_ theta(x)$|$P_\theta(X=x_i)$]] 的结果很显然为 0, 所以需要换一种定义.

### VAE (变分自编码器)中的假设

这是一个 VAE 生成图像的过程.

![](https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20240530105437.png)

在 VAE 中, 有如下假设.

1. 参数设定
	1. 噪声 $z_i$, 
	2. 模型 $G$ 
	3. 模型生成出的图像为 $G(z_i)$.
2. 假设的描述
	1. 给定噪声 $z_i$, 模型 $G$ 生成的图像 $G(z_i)$ 是某个高斯分布的均值
	2. $P_\theta(X| Z)$ 服从于某个高斯分布, 即假设模型生成图像的这个行为是服从高斯分布的
		1. 而非生成的图像是服从某个高斯分布的
3. 假设的解释：为何可以假设为高斯分布？
	1. 在解释假设之前, 我们应该明确的是, 
		1. $P_\theta(X| Z)$ 服从于某个高斯分布, 指的是模型生成图像的「这个行为」是服从高斯分布的
		2. 而非「生成的图像」是服从某个高斯分布的
			1. 图像服从的分布十分复杂, 不是能用高斯分布解释的
			2. 我们只能用高斯分布解释「生成模型 $G$ 的行为」, 即「 $G$ 生成图像的规律」

根据这个假设, 我们可以写出 $P_\theta(X|Z)$ 满足的概率密度, 如下

$$
P_\theta(X|Z) \sim N\left(G(z),\sigma^2\right)
$$
即
$$
P_\theta(X|Z) = \frac{1}{\sqrt{2\pi}\sigma^2}\exp\left[-\frac{1}{2}\cdot\left(\frac{X-G(Z)}{\sigma}\right)^2\right]
$$

从而有
$$
P_\theta(X|Z)\propto \exp(-\Vert X-G(Z)\Vert_2^2)
$$

进一步来说, 如果模型生成的图像 $G(Z)$ 与 $X$ 越接近, 则概率 $P_\theta(X|Z)$ 越大.

这是一件有些显然确有有些匪夷所思的事实.
1. 有些显然：如果生成的图像 $G(Z)$ 与真实图像 $X$ 越接近, 确实表示网络生成真实图像的能力越强
2. 有些匪夷所思：与一般的概率密度不一样. 一般的概率密度中, 变化的是随机变量 $X$；而在 VAE 中, 变化的是均值 $G(Z)$ 
	1. 一般的概率密度中, 随机变量 $X$ 是一个变化的量, 而均值是一个不变的量. 当随机变量与 $X$ 越接近时, 概率密度越大. 在概率密度附近的积分, 即概率越大
	2. 而在 VAE 中, 随机变量 $X$ 是一个定值, 而均值 $G(Z)$ 是一个变化的量. 当均值 $G(Z)$ 变化时, 即模型生成的图像变化时, 整个概率概率密度 $P_\theta(X|Z)$ 的对称轴会发生变化.
		1. 当这个均值与真实图像 $X$ 越接近, 则 $P_\theta(X|Z)$ 的概率越大.

在上面这个假设下, $P_\theta(X|Z)$ 被认为是服从 $\mathcal{N}\left(G(Z),\sigma^2\right)$ 的概率分布, 所以当真实图像 $X=x_i$ 与概率密度的均值 $G(Z)$ 已知的前提下, 概率密度 $P_\theta(X|Z)$ 也变得可以计算了.

在 $P_\theta(X|Z)$ 可计算后, $P_\theta(X)$ 也可以直接计算了, [[扩散模型过程整理-NekasuPCschool]]