# 生成式 AI 的缘起、机遇与发展_邓成

### 生成式 AI 的理论基础

#### 发展基石

1. VAE 与流模型、GAN、扩散模型与自回归网络

#### 自回归模型

出发点为给图像构建一个概率分布

#### 流模型

构造一个双射函数, 用于在简单分布与复杂分布之间相互转换

使用多个双射函数提升模型的泛化能力

#### VAE 与扩散模型


#### 生成对抗网络 GAN

使用博弈的思想, 判别器与生成器通过博弈相互提升性能

#### 扩散模型

来源于物理学中的非平衡的物理学扩散过程

分为两个过程：正向的加噪过程与逆向的去噪过程

## 生成式 AI 的发展历程

1. 智能涌现：2023 年的 ChatGPT, 生成式大模型出现“智能涌现”
2. 文本生成：Kimi (月之暗面公司)与 ChatGPT (OpenAI 公司) 
3. 图像生成：
	1. 埃德孟贝拉米画像, 使用 GAN 基于数万上图像生成
	2. Stable diffusion：太有名了, 不介绍了
	3. AnimateDIff：一个 Diffusion 模型的应用, 生成高清短视频
	4. 多样化条件生成 ControlNet：一个 Diffusion 模型的应用, 给模型不同的条件, 可以根据条件进行图像的生成
		1. 可以输入深度预测图像
	5. Animate Anyone：根据人体姿态信息生成不同的人体视频 (如舞蹈)
	6. SORA：文本到视频的生成模型
4. 音频生成：
	1. Suno V3

## 个人工作

公司的大模型这么厉害, 高校的学生老师能做些什么呢？

### 代表性工作 1：文生图

对一个图像有不同的表达, 但是同一表达可能指的是相同的物体. 在这个前提下, 语义与生成内容的关系、以及探讨语言的变化与生成图像质量的关系


### 少样本的模型生成适应

图像生成任务中, 如何将模型迁移到一个样本较小的图像风格中？

试图将 Adapter 引入, 改善了这个问题

### 代表性工作 3：基于大语言模型的演讲者手势生成

将人的手势当作一种语言, 将其离散化并编码, 输入进大模型进行训练.

## 未来展望

1. 局限性 1：生成模型的训练成本问题：生成式大模型的训练需要大量的计算资源和数据量. 这可能导致高昂的训练成本与时间. 同时这也导致了生成式大模型难以更新. 并且无法应用于更加细化的下游任务
	1. 大模型, 但是通常对于某种特定领域的数据缺乏了解, 同时高昂的训练代价使大模型难以应用到各种特定领域中
2. 局限性 2 ：生成模型的安全风险问题.
3. 局限性 3：生成模型的物理实现性问题. 生成模型无法理解现实的物理原理

1. 趋势 1：模型的规模与能力的不断提升, 伴随训练代价与成本的提升. 如何缓解训练代价与计算成本问题. 如何实现低成本的计算？可能从数学角度进行优化, 剪枝、云端大模型与本地小模型的协同工作, 大模型在中断的部署
2. 趋势 3：生成模型的偏差去除
3. 趋势 4：生成模型的安全性问题. 生成技术的快速发展为人类社会带来了可能的“虚假信息的冲击”. 如何提高生成模型的安全性问题也是值得思考的. 可能可以通过给模型添加水印的方式, 更好的监管生成式模型.

## 问题：在小样本的情况下如何进行训练--以草图生成家具模型为例

两个思路：
1.  借助基础模型, 如 ClIP 的知识等
2. 固有思路为“需要生对的数据”, 借助大模型可能可以利用“非对称非成对出现”的技术

# 机器人行为视觉建模研究_郑伟诗

